{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color=lightseagreen>Research questions:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__1. Are there a best and a worst day of the months to invest in (buy stocks from) <font color=deeppink>the MSCI world index</font> and <font color=deeppink>S&P 500</font>?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__2. If question 1 is proven to be true, will the following factors have an effect on them:__\n",
    "> - __`time`__: do the best and the worst day move over the years or they stay constant. \n",
    "> - __`federal holidays of the year`__: for this project we will focus first on public holidays of the US\n",
    "> - how about __`corona crisis`__?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__3. If they indeed move, by how much have they moved?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__4. Will we see similar effect based on daytime?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__5. As rumour has it, May and/or October might be the sour months for stock investment. Is this really true?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__6. Will blue-chip stocks like <font color=deeppink>Apple, Microsoft, Google, etc...</font> follow the same trend, wrt worst and best day for stock purchases?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color=lightseagreen>Chosen datasets:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the research questions above, the relevant data would logically be, and limited to (for scope setting), the following:\n",
    "1. Financial data of: <font color=lightseagreen>(by using yfinance API)</font>\n",
    "    1. MSCI world index\n",
    "    2. S&P 500\n",
    "    3. Apple\n",
    "    4. Microsoft\n",
    "    5. Google\n",
    "2. Public holidays of the US <font color=lightseagreen>(via web-scraping)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Notes:__\n",
    "> 1. As I am more interested in effect over a long period of time, the lowest granularity level of my data is __`per day`__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 2. Thus research question 4 will be parked as secondary/for later. Besides, with intra-day data granularity, yfinance has limitation --> another API might be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color=lightseagreen>The most important things I have learned:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. How to work with yfinance API/library via python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Various data granularity levels that can be extracted via yfinance and the limitation associated with them\n",
    "    1. 1m data is only available for last 7 days\n",
    "    2. data interval <1d for the last 60 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Regarding web-scraping, important to check the robots.text before scraping\n",
    "> wed-scraping from `https://www.nationaldayarchives.com/day-category/official-holidays-us/` --> `forbidden access`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. How to work with python module Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. How to use markdown syntax in jupyter notebook/RISE slideshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "6. Some learning with text handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color=lightseagreen>Challenges:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Not so much in extracting the stock data, since the API yfinance is quite handy and simple to use. The data extracted is very well organized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. The biggest challenge is to find interesting research questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Still left with uncertain feeling if dealing with stock data is the right choice for this project, since it is quite a well-studied area <font color=deeppink>(everybody loves money ðŸ˜Š)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Matching federal holidays with date ranging from 1927 to 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. Still have one thing left to do:\n",
    "> mark the adjacent date to the federal holidays when the stock market is actually closed (e.g. Thanksgiving, New Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color=lightseagreen>Codes:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### <font color=lightseagreen>Downloading financial data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl.workbook import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['MSCI', '^GSPC', 'AAPL', 'MSFT', 'GOOG']\n",
    "concat = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    dataset = yf.download(ticker, period='max')\n",
    "    dataset['Company'] = ticker\n",
    "    concat = pd.concat([concat, dataset], ignore_index=False)\n",
    "\n",
    "concat.reset_index(inplace=True)\n",
    "\n",
    "# date_col = pd.to_datetime(concat['Date'])\n",
    "# concat.drop(columns=['Date'], inplace=True)\n",
    "# final_df = pd.concat([concat, date_col], axis=1, ignore_index=False)\n",
    "# final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^GSPC    23453\n",
       "AAPL     10191\n",
       "MSFT      8865\n",
       "GOOG      4213\n",
       "MSCI      3396\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat.Company.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color=lightseagreen>Webscraping US federal holidays</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Federal_holidays_in_the_United_States'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')\n",
    "fed_holidays_table = tables[1]   # \"list of federal holidays\" is located at position 1 on tables sequence\n",
    "fed_holidays_data = fed_holidays_table.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# extracting the first column of table data\n",
    "dates = [fed_holidays_data[i].text for i in range(len(fed_holidays_data)) if i%3==0] \n",
    "\n",
    "# removing the parentheses from each item in the list\n",
    "new_dates = [date.replace('(', '').replace(')', '') for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# this is to separate the fixed holidays and the floating holidays from each other for further processing\n",
    "fixed = [date.split(' Fixed')[0] for date in new_dates if len(date.split(' ')) == 3]\n",
    "floating = [date for date in new_dates if len(date.split(' ')) > 3]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# extracting the lowest and highest year from the stock dataset \"concat\"\n",
    "years = concat['Date'].apply(lambda x: x.strftime('%Y'))\n",
    "min_year = int(min(years))\n",
    "max_year = int(max(years))\n",
    "years_range = list(range(min_year, max_year+1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# dealing with the floating holidays\n",
    "# an item in the floating list is a string like so 'February 15-27 Floating Monday'\n",
    "fed_holidays = []\n",
    "for year in years_range:\n",
    "    for item in floating:\n",
    "        split = re.findall('(\\w+)', item) # split the string at white space\n",
    "        min_day = int(split[1])           # extract the first number\n",
    "        max_day = int(split[2])+1         # extract the second number\n",
    "        for i in range(min_day, max_day): \n",
    "            date = ' '.join([split[0], str(i)])\n",
    "            date = ', '.join([date, str(year)])\n",
    "            date = datetime.strptime(date, '%B %d, %Y')  # '%B %d, %Y' format is equivalent to 'January 22, 1984'\n",
    "            # to check which date in the range is equivalent to the last word in the floating item, e.g. 'Monday'\n",
    "            if date.strftime(\"%A\")==split[-1]:           # '%A' to extract the day, e.g. 'Monday'\n",
    "                fed_holidays.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# dealing with the fixed holidays\n",
    "for year in years_range:\n",
    "    for i in fixed:\n",
    "        date_str = ', '.join([i, str(year)])\n",
    "        date = datetime.strptime(date_str, '%B %d, %Y')\n",
    "        fed_holidays.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this step is necessary to turn the fed holidays into pandas timestamp dtype. \n",
    "# this allows for mapping with the date column in the stock dataset 'concat'\n",
    "df = pd.DataFrame(fed_holidays, columns=['Date'])\n",
    "fed_holidays = df['Date'].tolist()\n",
    "\n",
    "# creating a dict based on fed_holidays list: \n",
    "# the keys will be the timestamps from the list itself\n",
    "# the values will be just the word 'Yes'\n",
    "new_dict = dict(zip(fed_holidays, ['Yes']*len(fed_holidays)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     49629\n",
       "Yes      494\n",
       "Name: Holiday, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the new_dict with the column 'Date' in concat to indicate if a date is a fed holiday or not.\n",
    "# new column 'Holiday' is created to contain only 'Yes', when a date is a holiday and np.nan, when there is no match\n",
    "concat['Holiday'] = concat['Date'].map(new_dict)\n",
    "\n",
    "# filling the non-Yes cells in Holiday column with No\n",
    "cond = concat['Holiday']!='Yes'\n",
    "concat.loc[cond, ['Holiday']] = 'No'\n",
    "\n",
    "# checking if column 'Holiday' indeed contains 'Yes' and np.nan\n",
    "concat.Holiday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# writing the dataset concat to an excel file\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "for r in dataframe_to_rows(concat, index=False, header=True):\n",
    "    ws.append(r)\n",
    "wb.save('../data-folder/dataset.xlsx')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "90%",
   "width": "90%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
